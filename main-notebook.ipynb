{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bangkit Assigment: Lung Disease Classification with Machine Learning\n",
    "This is an initial commit of the notebook, please add more things here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab library to upload files to notebook\n",
    "from google.colab import files\n",
    "\n",
    "# Install Kaggle library\n",
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload kaggle API key file\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downlaod dataset from upstream\n",
    "!kaggle datasets download -d vbookshelf/respiratory-sound-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move credential API to kaggle path\n",
    "!cp kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip dataset into a folder\n",
    "!unzip respiratory-sound-database.zip -d dataset\n",
    "!rm respiratory-sound-database.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for processing\n",
    "import wave\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_diagnosis = pd.read_csv('dataset/demographic_info.txt', names = \n",
    "                 ['Patient number', 'Age', 'Sex' , 'Adult BMI (kg/m2)', 'Child Weight (kg)' , 'Child Height (cm)'],\n",
    "                 delimiter = ' ')\n",
    "\n",
    "diagnosis = pd.read_csv('dataset/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv', names = ['Patient number', 'Diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine diagnosis data with patient data\n",
    "df =  df_no_diagnosis.join(diagnosis.set_index('Patient number'), on = 'Patient number', how = 'left')\n",
    "df['Diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'dataset/respiratory_sound_database/Respiratory_Sound_Database/audio_and_txt_files/'\n",
    "filenames = [s.split('.')[0] for s in os.listdir(path = root) if '.txt' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Annotation_Data(file_name, root):\n",
    "    tokens = file_name.split('_')\n",
    "    recording_info = pd.DataFrame(data = [tokens], columns = ['Patient number', 'Recording index', 'Chest location','Acquisition mode','Recording equipment'])\n",
    "    recording_annotations = pd.read_csv(os.path.join(root, file_name + '.txt'), names = ['Start', 'End', 'Crackles', 'Wheezes'], delimiter= '\\t')\n",
    "    return (recording_info, recording_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_list = []\n",
    "rec_annotations = []\n",
    "rec_annotations_dict = {}\n",
    "for s in filenames:\n",
    "    (i,a) = Extract_Annotation_Data(s, root)\n",
    "    i_list.append(i)\n",
    "    rec_annotations.append(a)\n",
    "    rec_annotations_dict[s] = a\n",
    "recording_info = pd.concat(i_list, axis = 0)\n",
    "recording_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_label_list = []\n",
    "crack_list = []\n",
    "wheeze_list = []\n",
    "both_sym_list = []\n",
    "filename_list = []\n",
    "for f in filenames:\n",
    "    d = rec_annotations_dict[f]\n",
    "    no_labels = len(d[(d['Crackles'] == 0) & (d['Wheezes'] == 0)].index)\n",
    "    n_crackles = len(d[(d['Crackles'] == 1) & (d['Wheezes'] == 0)].index)\n",
    "    n_wheezes = len(d[(d['Crackles'] == 0) & (d['Wheezes'] == 1)].index)\n",
    "    both_sym = len(d[(d['Crackles'] == 1) & (d['Wheezes'] == 1)].index)\n",
    "    no_label_list.append(no_labels)\n",
    "    crack_list.append(n_crackles)\n",
    "    wheeze_list.append(n_wheezes)\n",
    "    both_sym_list.append(both_sym)\n",
    "    filename_list.append(f)\n",
    "\n",
    "file_label_df = pd.DataFrame(data = {'filename':filename_list, 'no label':no_label_list, 'crackles only':crack_list, 'wheezes only':wheeze_list, 'crackles and wheezees':both_sym_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_labels = file_label_df[(file_label_df['crackles only'] != 0) | (file_label_df['wheezes only'] != 0) | (file_label_df['crackles and wheezees'] != 0)]\n",
    "file_label_df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy.io.wavfile as wf\n",
    "#wave file reader\n",
    "\n",
    "#Will resample all files to the target sample rate and produce a 32bit float array\n",
    "def read_wav_file(str_filename, target_rate):\n",
    "    wav = wave.open(str_filename, mode = 'r')\n",
    "    (sample_rate, data) = extract2FloatArr(wav,str_filename)\n",
    "    \n",
    "    if (sample_rate != target_rate):\n",
    "        ( _ , data) = resample(sample_rate, data, target_rate)\n",
    "        \n",
    "    wav.close()\n",
    "    return (target_rate, data.astype(np.float32))\n",
    "\n",
    "def resample(current_rate, data, target_rate):\n",
    "    x_original = np.linspace(0,100,len(data))\n",
    "    x_resampled = np.linspace(0,100, int(len(data) * (target_rate / current_rate)))\n",
    "    resampled = np.interp(x_resampled, x_original, data)\n",
    "    return (target_rate, resampled.astype(np.float32))\n",
    "\n",
    "# -> (sample_rate, data)\n",
    "def extract2FloatArr(lp_wave, str_filename):\n",
    "    (bps, channels) = bitrate_channels(lp_wave)\n",
    "    \n",
    "    if bps in [1,2,4]:\n",
    "        (rate, data) = wf.read(str_filename)\n",
    "        divisor_dict = {1:255, 2:32768}\n",
    "        if bps in [1,2]:\n",
    "            divisor = divisor_dict[bps]\n",
    "            data = np.divide(data, float(divisor)) #clamp to [0.0,1.0]        \n",
    "        return (rate, data)\n",
    "    \n",
    "    elif bps == 3: \n",
    "        #24bpp wave\n",
    "        return read24bitwave(lp_wave)\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Unrecognized wave format: {} bytes per sample'.format(bps))\n",
    "        \n",
    "#Note: This function truncates the 24 bit samples to 16 bits of precision\n",
    "#Reads a wave object returned by the wave.read() method\n",
    "#Returns the sample rate, as well as the audio in the form of a 32 bit float numpy array\n",
    "#(sample_rate:float, audio_data: float[])\n",
    "def read24bitwave(lp_wave):\n",
    "    nFrames = lp_wave.getnframes()\n",
    "    buf = lp_wave.readframes(nFrames)\n",
    "    reshaped = np.frombuffer(buf, np.int8).reshape(nFrames,-1)\n",
    "    short_output = np.empty((nFrames, 2), dtype = np.int8)\n",
    "    short_output[:,:] = reshaped[:, -2:]\n",
    "    short_output = short_output.view(np.int16)\n",
    "    return (lp_wave.getframerate(), np.divide(short_output, 32768).reshape(-1))  #return numpy array to save memory via array slicing\n",
    "\n",
    "def bitrate_channels(lp_wave):\n",
    "    bps = (lp_wave.getsampwidth() / lp_wave.getnchannels()) #bytes per sample\n",
    "    return (bps, lp_wave.getnchannels())\n",
    "\n",
    "def slice_data(start, end, raw_data,  sample_rate):\n",
    "    max_ind = len(raw_data) \n",
    "    start_ind = min(int(start * sample_rate), max_ind)\n",
    "    end_ind = min(int(end * sample_rate), max_ind)\n",
    "    return raw_data[start_ind: end_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_list = []\n",
    "for i in range(len(rec_annotations)):\n",
    "    current = rec_annotations[i]\n",
    "    duration = current['End'] - current['Start']\n",
    "    duration_list.extend(duration)\n",
    "\n",
    "duration_list = np.array(duration_list)\n",
    "plt.hist(duration_list, bins = 50)\n",
    "print('longest cycle:{}'.format(max(duration_list)))\n",
    "print('shortest cycle:{}'.format(min(duration_list)))\n",
    "threshold = 5\n",
    "print('Fraction of samples less than {} seconds:{}'.format(threshold,\n",
    "                                                           np.sum(duration_list < threshold)/len(duration_list)))"
   ]
  }
 ]
}