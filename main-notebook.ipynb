{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "Copy of main-notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTRg0YlrZ_HF",
        "colab_type": "text"
      },
      "source": [
        "# Bangkit Assigment: Lung Disease Classification with Machine Learning\n",
        "This is an initial commit of the notebook, please add more things here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxvy0XI5Z_HJ",
        "colab_type": "text"
      },
      "source": [
        "## Importing Data from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XndzcFCQhlpf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "eea8d654-5847-4989-dc70-c6255e859f36"
      },
      "source": [
        "#!pip uninstall keras\n",
        "!pip install keras==2.3.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.3.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.18.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY4tQc51Z_HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Colab library to upload files to notebook\n",
        "from google.colab import files\n",
        "\n",
        "# Install Kaggle library\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K_vkmpJZ_HT",
        "colab_type": "code",
        "outputId": "56b0fbdd-156d-42e4-b9db-c5418609ec07",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Upload kaggle API key file\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-94cbebbe-9e1f-4456-a8da-8de4a54e2b3f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-94cbebbe-9e1f-4456-a8da-8de4a54e2b3f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aazdYBrb6jO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoJOBQp2Z_Hc",
        "colab_type": "code",
        "outputId": "fbd1d427-56ef-4fa3-99aa-24ca35850664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%%time\n",
        "# Download dataset from upstream\n",
        "!kaggle datasets download -d vbookshelf/respiratory-sound-database"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading respiratory-sound-database.zip to /content\n",
            "100% 3.67G/3.69G [00:45<00:00, 106MB/s] \n",
            "100% 3.69G/3.69G [00:45<00:00, 86.4MB/s]\n",
            "CPU times: user 498 ms, sys: 89.8 ms, total: 588 ms\n",
            "Wall time: 47.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl0FfDFXZ_Hs",
        "colab_type": "code",
        "outputId": "24a353b2-8de1-4e28-903f-6cd56372669f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "%%time\n",
        "# Unzip dataset into a folder\n",
        "!unzip respiratory-sound-database.zip -d dataset\n",
        "!rm respiratory-sound-database.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  respiratory-sound-database.zip\n",
            "replace dataset/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/101_1b1_Al_sc_Meditron.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "CPU times: user 1.22 s, sys: 152 ms, total: 1.38 s\n",
            "Wall time: 4min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCEPDYONZ_Hz",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKaSojlLZ_H0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary libraries for processing\n",
        "import wave\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZSjIYZdZ_H8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_no_diagnosis = pd.read_csv('dataset/demographic_info.txt', names = \n",
        "                 ['Patient number', 'Age', 'Sex' , 'Adult BMI (kg/m2)', 'Child Weight (kg)' , 'Child Height (cm)'],\n",
        "                 delimiter = ' ')\n",
        "\n",
        "diagnosis = pd.read_csv('dataset/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv', names = ['Patient number', 'Diagnosis'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbzW_jdsZ_IB",
        "colab_type": "code",
        "outputId": "b17de116-1fc2-44c7-bdc6-a5def2e21423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Combine diagnosis data with patient data\n",
        "df =  df_no_diagnosis.join(diagnosis.set_index('Patient number'), on = 'Patient number', how = 'left')\n",
        "df['Diagnosis'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "COPD              64\n",
              "Healthy           26\n",
              "URTI              14\n",
              "Bronchiectasis     7\n",
              "Bronchiolitis      6\n",
              "Pneumonia          6\n",
              "LRTI               2\n",
              "Asthma             1\n",
              "Name: Diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWBA6bDGZ_IE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = 'dataset/respiratory_sound_database/Respiratory_Sound_Database/audio_and_txt_files/'\n",
        "filenames = [s.split('.')[0] for s in os.listdir(path = root) if '.txt' in s]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRjboeF_Z_II",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Extract_Annotation_Data(file_name, root):\n",
        "    tokens = file_name.split('_')\n",
        "    recording_info = pd.DataFrame(data = [tokens], columns = ['Patient number', 'Recording index', 'Chest location','Acquisition mode','Recording equipment'])\n",
        "    recording_annotations = pd.read_csv(os.path.join(root, file_name + '.txt'), names = ['Start', 'End', 'Crackles', 'Wheezes'], delimiter= '\\t')\n",
        "    return (recording_info, recording_annotations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7u1WkeEZ_IP",
        "colab_type": "code",
        "outputId": "f59ebc9e-f41c-4838-de18-82eacd7a804d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "i_list = []\n",
        "rec_annotations = []\n",
        "rec_annotations_dict = {}\n",
        "for s in filenames:\n",
        "    (i,a) = Extract_Annotation_Data(s, root)\n",
        "    i_list.append(i)\n",
        "    rec_annotations.append(a)\n",
        "    rec_annotations_dict[s] = a\n",
        "recording_info = pd.concat(i_list, axis = 0)\n",
        "recording_info.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Patient number</th>\n",
              "      <th>Recording index</th>\n",
              "      <th>Chest location</th>\n",
              "      <th>Acquisition mode</th>\n",
              "      <th>Recording equipment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>174</td>\n",
              "      <td>2p3</td>\n",
              "      <td>Pl</td>\n",
              "      <td>mc</td>\n",
              "      <td>AKGC417L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>185</td>\n",
              "      <td>1b1</td>\n",
              "      <td>Ar</td>\n",
              "      <td>sc</td>\n",
              "      <td>Litt3200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>203</td>\n",
              "      <td>1p4</td>\n",
              "      <td>Pl</td>\n",
              "      <td>mc</td>\n",
              "      <td>AKGC417L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>147</td>\n",
              "      <td>2b3</td>\n",
              "      <td>Al</td>\n",
              "      <td>mc</td>\n",
              "      <td>AKGC417L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>163</td>\n",
              "      <td>2b2</td>\n",
              "      <td>Pr</td>\n",
              "      <td>mc</td>\n",
              "      <td>AKGC417L</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Patient number Recording index  ... Acquisition mode Recording equipment\n",
              "0            174             2p3  ...               mc            AKGC417L\n",
              "0            185             1b1  ...               sc            Litt3200\n",
              "0            203             1p4  ...               mc            AKGC417L\n",
              "0            147             2b3  ...               mc            AKGC417L\n",
              "0            163             2b2  ...               mc            AKGC417L\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIXijKJqZ_IX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_label_list = []\n",
        "crack_list = []\n",
        "wheeze_list = []\n",
        "both_sym_list = []\n",
        "filename_list = []\n",
        "for f in filenames:\n",
        "    d = rec_annotations_dict[f]\n",
        "    no_labels = len(d[(d['Crackles'] == 0) & (d['Wheezes'] == 0)].index)\n",
        "    n_crackles = len(d[(d['Crackles'] == 1) & (d['Wheezes'] == 0)].index)\n",
        "    n_wheezes = len(d[(d['Crackles'] == 0) & (d['Wheezes'] == 1)].index)\n",
        "    both_sym = len(d[(d['Crackles'] == 1) & (d['Wheezes'] == 1)].index)\n",
        "    no_label_list.append(no_labels)\n",
        "    crack_list.append(n_crackles)\n",
        "    wheeze_list.append(n_wheezes)\n",
        "    both_sym_list.append(both_sym)\n",
        "    filename_list.append(f)\n",
        "\n",
        "file_label_df = pd.DataFrame(data = {'filename':filename_list, 'no label':no_label_list, 'crackles only':crack_list, 'wheezes only':wheeze_list, 'crackles and wheezees':both_sym_list})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cP4W2sLZ_Ic",
        "colab_type": "code",
        "outputId": "1b6a7e64-2b12-4342-e110-77a78d8294b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "w_labels = file_label_df[(file_label_df['crackles only'] != 0) | (file_label_df['wheezes only'] != 0) | (file_label_df['crackles and wheezees'] != 0)]\n",
        "file_label_df.sum()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "filename                 174_2p3_Pl_mc_AKGC417L185_1b1_Ar_sc_Litt320020...\n",
              "no label                                                              3642\n",
              "crackles only                                                         1864\n",
              "wheezes only                                                           886\n",
              "crackles and wheezees                                                  506\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KahYfcC0Z_Ih",
        "colab_type": "text"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s_QtrZxZ_Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import scipy.io.wavfile as wf\n",
        "#wave file reader\n",
        "\n",
        "#Will resample all files to the target sample rate and produce a 32bit float array\n",
        "def read_wav_file(str_filename, target_rate):\n",
        "    wav = wave.open(str_filename, mode = 'r')\n",
        "    (sample_rate, data) = extract2FloatArr(wav,str_filename)\n",
        "    \n",
        "    if (sample_rate != target_rate):\n",
        "        ( _ , data) = resample(sample_rate, data, target_rate)\n",
        "        \n",
        "    wav.close()\n",
        "    return (target_rate, data.astype(np.float32))\n",
        "\n",
        "def resample(current_rate, data, target_rate):\n",
        "    x_original = np.linspace(0,100,len(data))\n",
        "    x_resampled = np.linspace(0,100, int(len(data) * (target_rate / current_rate)))\n",
        "    resampled = np.interp(x_resampled, x_original, data)\n",
        "    return (target_rate, resampled.astype(np.float32))\n",
        "\n",
        "# -> (sample_rate, data)\n",
        "def extract2FloatArr(lp_wave, str_filename):\n",
        "    (bps, channels) = bitrate_channels(lp_wave)\n",
        "    \n",
        "    if bps in [1,2,4]:\n",
        "        (rate, data) = wf.read(str_filename)\n",
        "        divisor_dict = {1:255, 2:32768}\n",
        "        if bps in [1,2]:\n",
        "            divisor = divisor_dict[bps]\n",
        "            data = np.divide(data, float(divisor)) #clamp to [0.0,1.0]        \n",
        "        return (rate, data)\n",
        "    \n",
        "    elif bps == 3: \n",
        "        #24bpp wave\n",
        "        return read24bitwave(lp_wave)\n",
        "    \n",
        "    else:\n",
        "        raise Exception('Unrecognized wave format: {} bytes per sample'.format(bps))\n",
        "        \n",
        "#Note: This function truncates the 24 bit samples to 16 bits of precision\n",
        "#Reads a wave object returned by the wave.read() method\n",
        "#Returns the sample rate, as well as the audio in the form of a 32 bit float numpy array\n",
        "#(sample_rate:float, audio_data: float[])\n",
        "def read24bitwave(lp_wave):\n",
        "    nFrames = lp_wave.getnframes()\n",
        "    buf = lp_wave.readframes(nFrames)\n",
        "    reshaped = np.frombuffer(buf, np.int8).reshape(nFrames,-1)\n",
        "    short_output = np.empty((nFrames, 2), dtype = np.int8)\n",
        "    short_output[:,:] = reshaped[:, -2:]\n",
        "    short_output = short_output.view(np.int16)\n",
        "    return (lp_wave.getframerate(), np.divide(short_output, 32768).reshape(-1))  #return numpy array to save memory via array slicing\n",
        "\n",
        "def bitrate_channels(lp_wave):\n",
        "    bps = (lp_wave.getsampwidth() / lp_wave.getnchannels()) #bytes per sample\n",
        "    return (bps, lp_wave.getnchannels())\n",
        "\n",
        "def slice_data(start, end, raw_data,  sample_rate):\n",
        "    max_ind = len(raw_data) \n",
        "    start_ind = min(int(start * sample_rate), max_ind)\n",
        "    end_ind = min(int(end * sample_rate), max_ind)\n",
        "    return raw_data[start_ind: end_ind]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG2W8tvkZ_Il",
        "colab_type": "text"
      },
      "source": [
        "## Distribution of respiratory cycle lengths\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU4LiD_HZ_Im",
        "colab_type": "code",
        "outputId": "07061cd6-da2a-4d8c-8588-60550668f7ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "duration_list = []\n",
        "for i in range(len(rec_annotations)):\n",
        "    current = rec_annotations[i]\n",
        "    duration = current['End'] - current['Start']\n",
        "    duration_list.extend(duration)\n",
        "\n",
        "duration_list = np.array(duration_list)\n",
        "plt.hist(duration_list, bins = 50)\n",
        "print('longest cycle:{}'.format(max(duration_list)))\n",
        "print('shortest cycle:{}'.format(min(duration_list)))\n",
        "threshold = 5\n",
        "print('Fraction of samples less than {} seconds:{}'.format(threshold,\n",
        "                                                           np.sum(duration_list < threshold)/len(duration_list)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "longest cycle:16.163\n",
            "shortest cycle:0.20000000000000284\n",
            "Fraction of samples less than 5 seconds:0.9660771238040011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX5I6YuhLUkcMfUnqiKEvSR35fwjFNhsW4WXxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whXCm1z63zjj",
        "colab_type": "text"
      },
      "source": [
        "## Feature Extraction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6dSn7eZ35PK",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5YFqjz7dzQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_pad_len = 862 # to make the length of all MFCC equal\n",
        "\n",
        "#This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
        "# of the audio\n",
        "def extract_features_mfcc(file_name):\n",
        "    # try:\n",
        "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=20) \n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    padding_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, padding_width)), mode='constant')\n",
        "        \n",
        "    # except Exception as e:\n",
        "    #     print(\"Error encountered while parsing file: \", file_name)\n",
        "    #     return None \n",
        "     \n",
        "    return mfccs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnQhhIhpd1QF",
        "colab_type": "code",
        "outputId": "377cd53c-fbb7-451a-8e5b-36deca31fc29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "filenames = [f for f in listdir(root) if (isfile(join(root, f)) and f.endswith('.wav'))] \n",
        "\n",
        "filepaths = [join(root, f) for f in filenames] # full paths of files\n",
        "\n",
        "features = [] \n",
        "\n",
        "# Iterate through each sound file and extract the features\n",
        "for file_name in filepaths:\n",
        "    data = extract_features_mfcc(file_name)\n",
        "    if data is not None:\n",
        "      # print(data)\n",
        "      features.append(data)\n",
        "\n",
        "print('Finished feature extraction using MFCC from ', len(features), ' files')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished feature extraction using MFCC from  920  files\n",
            "CPU times: user 4min 20s, sys: 55.8 s, total: 5min 16s\n",
            "Wall time: 6min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD5-Rk8njtU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CHECKPOINT\n",
        "# np.save('features', features)\n",
        "# files.download('features.npy')\n",
        "%%time\n",
        "# Download dataset from upstream\n",
        "!kaggle datasets download -d risyadhasbullah/bangkit-features\n",
        "features = np.load('features.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWR4bkL3XUn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35467fea-f01a-46a5-cdce-309b7a84d724"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# patient IDs corresponding to each file\n",
        "p_id_in_file = [] \n",
        "for name in filenames:\n",
        "    p_id_in_file.append(int(name[:3]))\n",
        "\n",
        "# patient diagnosis file - Should use the file in the beginning of the notebook but it returns error\n",
        "p_diag = pd.read_csv('dataset/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv',header=None) \n",
        "\n",
        "p_id_in_file = np.array(p_id_in_file) \n",
        "\n",
        "# labels for audio files\n",
        "labels = np.array([p_diag[p_diag[0] == x][1].values[0] for x in p_id_in_file]) \n",
        "\n",
        "# Remove a very rare disease, it returns an error if we're not removing it\n",
        "labels_fix = np.delete(labels, np.where((labels == 'Asthma'))[0], axis=0)\n",
        "\n",
        "# One-hot encode labels\n",
        "le = LabelEncoder()\n",
        "i_labels = le.fit_transform(labels_fix)\n",
        "oh_labels = to_categorical(i_labels) \n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4NjbG77Qxke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7d54e4b-896e-4de7-f2a0-3dc99e57b629"
      },
      "source": [
        "# convert to numpy array\n",
        "features = np.array(features) \n",
        "\n",
        "# delete the very rare diseases\n",
        "features1 = np.delete(features, np.where((labels == 'Asthma'))[0], axis=0) \n",
        "\n",
        "# add channel dimension for CNN\n",
        "features1 = np.reshape(features1, (*features1.shape,1))\n",
        "print(features1.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(919, 40, 862, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfjroyadXnZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train test split = This is the data for training the model\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features1, oh_labels, stratify=oh_labels, \n",
        "                                                    test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDtn7JA2yEpe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b505d48b-1a4d-4a4d-efc1-14f8dca58c91"
      },
      "source": [
        "print(train_features.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(735, 40, 862, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAU8aL9Ok0Is",
        "colab_type": "text"
      },
      "source": [
        "## Build the Model Using CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuirV19phTix",
        "colab_type": "text"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U-oyjSuk3Oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 5\n",
        "n_epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3uze0EiTnmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Keras implementation\n",
        "from keras import Sequential, optimizers, backend\n",
        "from keras.layers import Conv3D, Dense, Activation, Dropout, MaxPool3D, Flatten, LeakyReLU\n",
        "import tensorflow as tf\n",
        "backend.clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv3D(128, [7,2,8], strides = [10,2, 10], padding = 'SAME', input_shape=train_features.shape))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(MaxPool3D(padding = 'SAME'))\n",
        "\n",
        "model.add(Conv3D(256, [10, 1, 8], padding = 'SAME'))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(MaxPool3D(padding = 'SAME'))\n",
        "\n",
        "model.add(Conv3D(256, [3, 1, 5], padding = 'SAME'))\n",
        "model.add(Conv3D(256, [5, 1, 6], padding = 'SAME'))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(MaxPool3D(padding = 'SAME'))\n",
        "\n",
        "model.add(Conv3D(512, [7, 2, 8], padding = 'SAME'))\n",
        "model.add(Conv3D(512, [3, 1, 5], padding = 'SAME',activation = 'relu'))\n",
        "model.add(Conv3D(512, [7, 2, 8], padding = 'SAME'))\n",
        "model.add(Conv3D(512, [3, 1, 5], padding = 'SAME', activation = 'relu'))\n",
        "model.add(MaxPool3D(padding = 'SAME'))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(4096, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dense(7, activation = 'softmax'))\n",
        "\n",
        "opt = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.00, amsgrad=False)\n",
        "\n",
        "model.compile(optimizer =  opt , loss = 'categorical_crossentropy', metrics = ['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFIPOKYjeYje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "f80036ab-4644-43a6-88a6-45aedf7854a2"
      },
      "source": [
        "%%time\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "print(n_epochs)\n",
        "print(batch_size)\n",
        "stats = model.fit_generator(ImageDataGenerator().flow(train_features, train_labels, batch_size=batch_size),\n",
        "                            steps_per_epoch=len(train_features),\n",
        "                            epochs=n_epochs)\n",
        "# stats = model.fit_generator(generator = train_gen.generate_keras(batch_size), \n",
        "#                             steps_per_epoch = train_gen.n_available_samples() // batch_size,\n",
        "#                             validation_data = test_gen.generate_keras(batch_size),\n",
        "#                             validation_steps = test_gen.n_available_samples() // batch_size, \n",
        "#                             epochs = n_epochs)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-f55ae432b155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from keras.preprocessing.image import ImageDataGenerator\\nprint(n_epochs)\\nprint(batch_size)\\nstats = model.fit_generator(ImageDataGenerator().flow(train_features, train_labels, batch_size=batch_size),\\n                            steps_per_epoch=len(train_features),\\n                            epochs=n_epochs)\\n# stats = model.fit_generator(generator = train_gen.generate_keras(batch_size), \\n#                             steps_per_epoch = train_gen.n_available_samples() // batch_size,\\n#                             validation_data = test_gen.generate_keras(batch_size),\\n#                             validation_steps = test_gen.n_available_samples() // batch_size, \\n#                             epochs = n_epochs)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    315\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvhat_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 \u001b[0mp_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm_t\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m           y = ops.convert_to_tensor_v2(\n\u001b[0;32m--> 988\u001b[0;31m               y, dtype_hint=x.dtype.base_dtype, name=\"y\")\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m           \u001b[0;31m# If the RHS is not a tensor, it might be a tensor aware object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1281\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                          as_ref=False):\n\u001b[1;32m    320\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    298\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    299\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    301\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: None values not supported."
          ]
        }
      ]
    }
  ]
}